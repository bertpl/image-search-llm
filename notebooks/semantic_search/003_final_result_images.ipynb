{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T17:22:51.160024Z",
     "start_time": "2025-06-29T17:22:51.156447Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# --- Go to correct starting folder ---\n",
    "# -------------------------------------\n",
    "# (when running jupyter lab in the browser, the notebook starts with CWD = folder where it is located, which breaks imports, ...)\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "while not ((cwd := pathlib.Path(os.getcwd())) / \"requirements.txt\").exists():\n",
    "    os.chdir(cwd.parent)  # go 1 folder up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ca2fc97b32c4c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T17:22:51.171607Z",
     "start_time": "2025-06-29T17:22:51.169518Z"
    }
   },
   "outputs": [],
   "source": [
    "# other imports\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from core.data import SearchResult\n",
    "from core.search import semantic_search, textual_search\n",
    "from notebooks.colors import CLR_BLACK, CLR_BLUE, CLR_DARK_GREEN, CLR_GREEN, CLR_GREY\n",
    "from notebooks.helpers import enable_metadata, get_data_folder, get_figures_folder, get_images_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aaab5f91cf1851",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "This notebook will run the 7 semantic search queries that we used in threshold analysis and will automatically split the results into 3 folders (TP, FP, TN) and resize all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e160457b9e907b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T17:22:51.189750Z",
     "start_time": "2025-06-29T17:22:51.184296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL FILES: 150\n",
      "GROUND TRUTH\n",
      "   dog        -> 2 results\n",
      "   coffee     -> 9 results\n",
      "   food       -> 36 results\n",
      "   sheep      -> 9 results\n",
      "   rabbit     -> 2 results\n",
      "   snow       -> 15 results\n",
      "   bike       -> 12 results\n"
     ]
    }
   ],
   "source": [
    "# queries we will test\n",
    "queries = [\"dog\", \"coffee\", \"food\", \"sheep\", \"rabbit\", \"snow\", \"bike\"]\n",
    "ground_truth: dict[str, list[str]] = dict()  # ground truth results (file names) for each query\n",
    "\n",
    "all_files = [file.name for file in get_images_folder().glob(\"*.jpg\")]\n",
    "print(f\"ALL FILES: {len(all_files)}\")\n",
    "\n",
    "for query in queries:\n",
    "    ground_truth_path = get_data_folder() / \"semantic_search\" / \"ground_truth\" / query\n",
    "    ground_truth[query] = [str(file.name) for file in ground_truth_path.glob(\"*.jpg\")]\n",
    "\n",
    "print(\"GROUND TRUTH\")\n",
    "for query, results in ground_truth.items():\n",
    "    print(f\"   {query.ljust(10)} -> {len(results)} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a4dfb20489d3f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T17:23:06.669391Z",
     "start_time": "2025-06-29T17:22:51.201845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: dog\n",
      "   processing image 1 - 2025.03.27-18.22.22-MOB-0001.jpg in dog/tp\n",
      "   processing image 2 - 2025.03.27-18.22.23-MOB-0001.jpg in dog/tp\n",
      "QUERY: coffee\n",
      "   processing image 1 - 2025.05.30-12.18.29-MOB-0001.jpg in coffee/tp\n",
      "   processing image 2 - 2025.05.30-12.18.57-MOB-0001.jpg in coffee/tp\n",
      "   processing image 3 - 2025.05.30-08.21.35-MOB-0001.jpg in coffee/tp\n",
      "   processing image 4 - 2025.06.03-11.13.11-MOB-0001.jpg in coffee/tp\n",
      "   processing image 5 - 2025.05.28-12.58.48-MOB-0001.jpg in coffee/tp\n",
      "   processing image 6 - 2025.05.28-12.58.37-MOB-0001.jpg in coffee/tp\n",
      "   processing image 7 - 2025.05.27-07.39.56-MOB-0001.jpg in coffee/tp\n",
      "   processing image 8 - 2025.06.02-07.56.55-MOB-0001.jpg in coffee/tp\n",
      "   processing image 1 - 2025.05.27-07.39.52-MOB-0001.jpg in coffee/fn\n",
      "QUERY: food\n",
      "   processing image 1 - 2025.05.24-17.33.49-MOB-0001.jpg in food/tp\n",
      "   processing image 2 - 2025.06.01-18.25.26-MOB-0001.jpg in food/tp\n",
      "   processing image 3 - 2025.05.26-18.25.44-MOB-0001.jpg in food/tp\n",
      "   processing image 4 - 2025.05.24-17.09.28-MOB-0001.jpg in food/tp\n",
      "   processing image 5 - 2025.06.01-18.44.23-MOB-0001.jpg in food/tp\n",
      "   processing image 6 - 2025.05.24-17.09.20-MOB-0001.jpg in food/tp\n",
      "   processing image 7 - 2025.05.30-08.10.04-MOB-0001.jpg in food/tp\n",
      "   processing image 8 - 2025.05.24-17.19.45-MOB-0001.jpg in food/tp\n",
      "   processing image 9 - 2025.05.28-18.11.38-MOB-0001.jpg in food/tp\n",
      "   processing image 10 - 2025.05.28-17.51.36-MOB-0001.jpg in food/tp\n",
      "   processing image 11 - 2025.06.02-18.16.26-MOB-0001.jpg in food/tp\n",
      "   processing image 12 - 2025.05.28-18.11.28-MOB-0001.jpg in food/tp\n",
      "   processing image 13 - 2025.05.30-08.09.55-MOB-0001.jpg in food/tp\n",
      "   processing image 14 - 2025.05.28-18.11.43-MOB-0001.jpg in food/tp\n",
      "   processing image 15 - 2025.05.24-17.33.44-MOB-0001.jpg in food/tp\n",
      "   processing image 16 - 2025.06.04-19.19.39-MOB-0001.jpg in food/tp\n",
      "   processing image 17 - 2025.05.26-18.25.36-MOB-0001.jpg in food/tp\n",
      "   processing image 18 - 2025.06.04-19.45.59-MOB-0001.jpg in food/tp\n",
      "   processing image 19 - 2025.05.24-17.33.42-MOB-0001.jpg in food/tp\n",
      "   processing image 20 - 2025.05.27-07.39.56-MOB-0001.jpg in food/tp\n",
      "   processing image 21 - 2025.06.01-18.44.15-MOB-0001.jpg in food/tp\n",
      "   processing image 22 - 2025.05.26-18.25.39-MOB-0001.jpg in food/tp\n",
      "   processing image 23 - 2025.06.02-07.56.55-MOB-0001.jpg in food/tp\n",
      "   processing image 24 - 2025.05.26-18.53.09-MOB-0001.jpg in food/tp\n",
      "   processing image 25 - 2025.06.03-17.26.51-MOB-0001.jpg in food/tp\n",
      "   processing image 26 - 2025.05.28-17.51.30-MOB-0001.jpg in food/tp\n",
      "   processing image 27 - 2025.05.28-08.15.48-MOB-0001.jpg in food/tp\n",
      "   processing image 28 - 2025.06.02-18.16.32-MOB-0001.jpg in food/tp\n",
      "   processing image 29 - 2025.05.28-18.11.23-MOB-0001.jpg in food/tp\n",
      "   processing image 30 - 2025.05.28-18.11.26-MOB-0001.jpg in food/tp\n",
      "   processing image 31 - 2025.05.28-12.58.48-MOB-0001.jpg in food/tp\n",
      "   processing image 32 - 2025.06.03-17.26.49-MOB-0001.jpg in food/tp\n",
      "   processing image 33 - 2025.05.27-07.39.52-MOB-0001.jpg in food/tp\n",
      "   processing image 34 - 2025.05.24-17.19.39-MOB-0001.jpg in food/tp\n",
      "   processing image 1 - 2025.05.30-07.36.18-MOB-0001.jpg in food/fp\n",
      "   processing image 1 - 2025.05.26-18.53.05-MOB-0001.jpg in food/fn\n",
      "   processing image 2 - 2025.05.28-12.58.37-MOB-0001.jpg in food/fn\n",
      "QUERY: sheep\n",
      "   processing image 1 - 2025.05.30-14.24.45-MOB-0001.jpg in sheep/tp\n",
      "   processing image 2 - 2025.05.30-10.43.21-MOB-0001.jpg in sheep/tp\n",
      "   processing image 3 - 2025.05.30-10.36.18-MOB-0001.jpg in sheep/tp\n",
      "   processing image 4 - 2025.05.30-10.43.18-MOB-0001.jpg in sheep/tp\n",
      "   processing image 5 - 2025.05.31-14.23.24-MOB-0001.jpg in sheep/tp\n",
      "   processing image 1 - 2025.05.30-10.36.26-MOB-0001.jpg in sheep/fn\n",
      "   processing image 2 - 2025.05.30-14.24.49-MOB-0001.jpg in sheep/fn\n",
      "   processing image 3 - 2025.05.30-10.35.50-MOB-0001.jpg in sheep/fn\n",
      "   processing image 4 - 2025.05.28-18.05.46-MOB-0001.jpg in sheep/fn\n",
      "QUERY: rabbit\n",
      "   processing image 1 - 2025.06.03-00.00.00-WAP-0001.jpg in rabbit/tp\n",
      "   processing image 2 - 2025.05.29-00.00.00-WAP-0007.jpg in rabbit/tp\n",
      "QUERY: snow\n",
      "   processing image 1 - 2024.12.25-10.48.04-MOB-0001.jpg in snow/tp\n",
      "   processing image 2 - 2024.12.25-09.49.26-MOB-0001.jpg in snow/tp\n",
      "   processing image 3 - 2024.12.25-11.29.50-MOB-0001.jpg in snow/tp\n",
      "   processing image 4 - 2024.12.25-11.46.59-MOB-0001.jpg in snow/tp\n",
      "   processing image 5 - 2024.12.25-11.52.44-MOB-0001.jpg in snow/tp\n",
      "   processing image 6 - 2024.12.25-12.16.27-MOB-0001.jpg in snow/tp\n",
      "   processing image 7 - 2024.12.25-11.39.43-MOB-0001.jpg in snow/tp\n",
      "   processing image 8 - 2024.12.25-11.52.47-MOB-0001.jpg in snow/tp\n",
      "   processing image 9 - 2024.12.25-10.48.01-MOB-0001.jpg in snow/tp\n",
      "   processing image 10 - 2025.02.24-07.04.21-MOB-0001.jpg in snow/tp\n",
      "   processing image 11 - 2025.02.24-07.04.27-MOB-0001.jpg in snow/tp\n",
      "   processing image 12 - 2025.02.24-07.04.29-MOB-0001.jpg in snow/tp\n",
      "   processing image 13 - 2025.02.24-07.07.24-MOB-0001.jpg in snow/tp\n",
      "   processing image 1 - 2025.02.24-07.07.19-MOB-0001.jpg in snow/fn\n",
      "   processing image 2 - 2025.02.24-07.07.04-MOB-0001.jpg in snow/fn\n",
      "QUERY: bike\n",
      "   processing image 1 - 2025.05.27-10.45.48-MOB-0001.jpg in bike/tp\n",
      "   processing image 2 - 2025.05.27-10.45.51-MOB-0001.jpg in bike/tp\n",
      "   processing image 3 - 2025.05.30-09.58.32-MOB-0001.jpg in bike/tp\n",
      "   processing image 4 - 2025.05.30-09.58.25-MOB-0001.jpg in bike/tp\n",
      "   processing image 5 - 2025.05.26-10.59.54-MOB-0001.jpg in bike/tp\n",
      "   processing image 6 - 2025.05.30-09.19.06-MOB-0001.jpg in bike/tp\n",
      "   processing image 7 - 2025.05.30-09.19.04-MOB-0001.jpg in bike/tp\n",
      "   processing image 8 - 2025.05.30-09.58.30-MOB-0001.jpg in bike/tp\n",
      "   processing image 9 - 2025.05.26-11.00.12-MOB-0001.jpg in bike/tp\n",
      "   processing image 10 - 2025.05.30-09.58.22-MOB-0001.jpg in bike/tp\n",
      "   processing image 1 - 2025.05.29-14.58.50-MOB-0001.jpg in bike/fn\n",
      "   processing image 2 - 2025.06.02-13.56.25-MOB-0001.jpg in bike/fn\n"
     ]
    }
   ],
   "source": [
    "def resize_img_to_max_dim(img: Image.Image, max_dim: int) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Resize an image to fit within a square of max_dim x max_dim pixels.\n",
    "    \"\"\"\n",
    "    width, height = img.size\n",
    "    if width > height:\n",
    "        new_width = max_dim\n",
    "        new_height = int(height * (max_dim / width))\n",
    "    else:\n",
    "        new_height = max_dim\n",
    "        new_width = int(width * (max_dim / height))\n",
    "\n",
    "    return img.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "\n",
    "def copy_image(src_filename: str, dst_file_index: str, query: str, result_type: str):\n",
    "    \"\"\"\n",
    "    Copy an image to the correct folder based on the query and result type (TP, FP, TN).\n",
    "    We copy one version that has max dimensions 1024 and one that has max dimensions 256.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"   processing image {dst_file_index} - {src_filename} in {query}/{result_type}\")\n",
    "\n",
    "    # --- load image ---\n",
    "    img_path = get_images_folder() / src_filename\n",
    "    img = Image.open(img_path)\n",
    "    img_small = resize_img_to_max_dim(img, max_dim=200)\n",
    "    img_large = resize_img_to_max_dim(img, max_dim=1000)\n",
    "\n",
    "    # --- save again ---\n",
    "    dst_folder = get_data_folder() / \"semantic_search\" / \"results\" / query / result_type\n",
    "    dst_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    img_small.save(dst_folder / f\"img_{dst_file_index:0>3}_small.jpg\", quality=90)\n",
    "    img_large.save(dst_folder / f\"img_{dst_file_index:0>3}_large.jpg\", quality=80)\n",
    "\n",
    "\n",
    "# go query by query\n",
    "for query in queries:\n",
    "    print(f\"QUERY: {query}\")\n",
    "\n",
    "    # --- perform query -----------------------------------\n",
    "    results = semantic_search(\n",
    "        directory=get_images_folder(),\n",
    "        query=query,\n",
    "        min_score=0.49,  # optimal value found in threshold analysis\n",
    "    )\n",
    "    result_filenames = [result.filename for result in results]\n",
    "\n",
    "    # --- split in TP, FP, TN -----------------------------\n",
    "    tp = [filename for filename in result_filenames if filename in ground_truth[query]]\n",
    "    fp = [filename for filename in result_filenames if filename not in ground_truth[query]]\n",
    "    fn = [filename for filename in ground_truth[query] if filename not in result_filenames]\n",
    "\n",
    "    # --- copy files --------------------------------------\n",
    "    for i, tp_filename in enumerate(tp, start=1):\n",
    "        copy_image(tp_filename, i, query, \"tp\")\n",
    "\n",
    "    for i, fp_filename in enumerate(fp, start=1):\n",
    "        copy_image(fp_filename, i, query, \"fp\")\n",
    "\n",
    "    for i, fn_filename in enumerate(fn, start=1):\n",
    "        copy_image(fn_filename, i, query, \"fn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
